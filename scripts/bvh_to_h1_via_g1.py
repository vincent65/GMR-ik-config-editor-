import argparse, os, pathlib, json, numpy as np, mujoco as mj, pickle
from general_motion_retargeting.utils.lafan1 import load_bvh_file
from general_motion_retargeting import GeneralMotionRetargeting as GMR
from general_motion_retargeting.params import IK_CONFIG_DICT, ROBOT_XML_DICT
from general_motion_retargeting.robot_motion_viewer import RobotMotionViewer

def compute_g1_skeletons(qpos_list, xml_path):
    model = mj.MjModel.from_xml_path(xml_path)
    data = mj.MjData(model)
    skeleton_frames = []
    for qpos in qpos_list:
        data.qpos[:] = qpos
        mj.mj_forward(model, data)
        frame = {}
        for body_id in range(model.nbody):
            name = mj.mj_id2name(model, mj.mjtObj.mjOBJ_BODY, body_id)
            frame[name] = (
                data.xpos[body_id].copy(),   # position
                data.xquat[body_id].copy(),  # orientation [w,x,y,z]
            )
        skeleton_frames.append(frame)
    return skeleton_frames

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--bvh_file", required=True)
    parser.add_argument("--g1_to_h1_config", required=True,
                        help="Path to your IK config generated by the editor (G1 -> H1).")
    parser.add_argument("--save_path", default=None,
                        help="Optional: where to save the resulting H1 motion .pkl")
    parser.add_argument("--motion_fps", type=int, default=30)
    parser.add_argument("--rate_limit", action="store_true", default=False)
    parser.add_argument("--record_video", action="store_true", default=False)
    parser.add_argument("--video_path", default="videos/g1_to_h1_test.mp4")
    args = parser.parse_args()

    # Stage 1: LAFAN1 -> G1
    lafan_frames, human_height = load_bvh_file(args.bvh_file, format="lafan1")
    g1_retarget = GMR(src_human="bvh_lafan1", tgt_robot="unitree_g1",
                      actual_human_height=human_height, verbose=False)

    g1_qpos_list = []
    for frame in lafan_frames:
        qpos = g1_retarget.retarget(frame)
        g1_qpos_list.append(qpos.copy())

    # Build G1 skeleton frames (positions/orientations) via MuJoCo FK
    g1_xml = str(ROBOT_XML_DICT["unitree_g1"])
    g1_skeleton_frames = compute_g1_skeletons(g1_qpos_list, g1_xml)

    # Stage 2: G1 -> H1 using your editor-generated config
    # Monkey-patch IK_CONFIG_DICT to register the new config under a custom key
    IK_CONFIG_DICT.setdefault("g1_robot", {})["unitree_h1"] = pathlib.Path(args.g1_to_h1_config)

    h1_retarget = GMR(src_human="g1_robot", tgt_robot="unitree_h1", verbose=False)

    h1_qpos_list = []
    for frame in g1_skeleton_frames:
        qpos = h1_retarget.retarget(frame)
        h1_qpos_list.append(qpos.copy())

    # Optional save
    if args.save_path:
        os.makedirs(os.path.dirname(args.save_path), exist_ok=True)
        root_pos = np.array([q[:3] for q in h1_qpos_list])
        root_rot = np.array([q[3:7][[1,2,3,0]] for q in h1_qpos_list])  # wxyz -> xyzw
        dof_pos  = np.array([q[7:] for q in h1_qpos_list])
        motion = dict(fps=args.motion_fps, root_pos=root_pos, root_rot=root_rot,
                      dof_pos=dof_pos, local_body_pos=None, link_body_list=None)
        with open(args.save_path, "wb") as f:
            pickle.dump(motion, f)
        print(f"Saved H1 motion to {args.save_path}")

    # Optional visualize
    viewer = RobotMotionViewer(robot_type="unitree_h1",
                               motion_fps=args.motion_fps,
                               transparent_robot=0,
                               record_video=args.record_video,
                               video_path=args.video_path)
    for qpos in h1_qpos_list:
        viewer.step(root_pos=qpos[:3], root_rot=qpos[3:7], dof_pos=qpos[7:],
                    human_motion_data=h1_retarget.scaled_human_data,
                    rate_limit=args.rate_limit, follow_camera=True)
    viewer.close()

if __name__ == "__main__":
    main()